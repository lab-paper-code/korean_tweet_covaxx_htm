{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aa839fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "#from hanspell import spell_checker\n",
    "from tqdm import tqdm\n",
    "import html\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef0b5c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_by_account(file_path, account_id):\n",
    "    with open(file_path, 'r', encoding='UTF8') as f:\n",
    "        accounts = f.read()\n",
    "    accounts = [i for i in accounts.split('\\n') if i]\n",
    "    accounts = list(map(lambda x: x.split(' '), accounts))\n",
    "    ids, name = zip(*accounts)\n",
    "    \n",
    "    if account_id in ids:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72f65a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_keyword_in(file_path, text):\n",
    "    with open(file_path, 'r', encoding='UTF8') as f:\n",
    "        keyword = f.read()\n",
    "    keyword = keyword.split('\\n')\n",
    "    for k in keyword:\n",
    "        if k in text:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c66e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_text(file_path, text):\n",
    "    with open(file_path, 'r', encoding='UTF8') as f:\n",
    "        replace = f.read()\n",
    "    replace = [i for i in replace.split('\\n') if i]\n",
    "    replace = list(map(lambda x: x.split(','), replace))\n",
    "\n",
    "    refined = html.unescape(text)\n",
    "    refined = refined.replace('xa0', ' ')\n",
    "    # refined = refined.replace('u200b', ' ')\n",
    "    refined = refined.replace('&39;', \"'\")\n",
    "    refined = re.sub(r'([U|u]0001f[a-zA-Z0-9]{3})|([U|u]200d)', '', refined)\n",
    "    refined = re.sub(r'@[a-zA-z0-9_]+', '', refined)\n",
    "    refined = re.sub(r'\\[[^)]*?\\]|\\<[^)]*?\\>|\\([^)]*?\\)', '', refined)\n",
    "    refined = re.sub(r'\\A(RT :) *', '', refined)\n",
    "    refined = re.sub(r'http[^ ]*', '', refined)\n",
    "\n",
    "    refined = refined.lower()\n",
    "    for old, new in replace:\n",
    "        refined = refined.replace(old.strip(), new.strip())\n",
    "\n",
    "    return ' '.join(refined.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22112a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'\n",
    "news_keyword_path = path + 'txt/' + 'news_keyword.txt'\n",
    "ads_keyword_path = path + 'txt/' + 'ads_keyword.txt'\n",
    "unrelated_keyword_path = path + 'txt/' + 'unrelated_keyword.txt'\n",
    "account_path = path + 'txt/' + 'account.txt'\n",
    "replace_path = path + 'txt/' + 'replace.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178dc6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all.json', 'r', encoding='UTF8') as f:\n",
    "        data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c55a6ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████| 1820235/1820235 [1:34:32<00:00, 320.87it/s]\n"
     ]
    }
   ],
   "source": [
    "ret = 0\n",
    "act = 0\n",
    "news = 0\n",
    "ads = 0\n",
    "unr = 0\n",
    "\n",
    "df = pd.DataFrame(columns=['date', 'time', 'twit', 'refined_twit', 'twit_id'])\n",
    "    # err = 0; normal = 0\n",
    "for i in tqdm(range(len(data))):\n",
    "    dummy = data[i]\n",
    "    if dummy['tag'] == 1: #리트윗 데이터이면 삭제\n",
    "        ret +=1\n",
    "        pass\n",
    "    elif remove_by_account(account_path, dummy['author_id']):\n",
    "        act +=1\n",
    "        pass\n",
    "    elif is_keyword_in(news_keyword_path, dummy['twit']):\n",
    "        news +=1\n",
    "        pass\n",
    "    elif is_keyword_in(ads_keyword_path, dummy['twit']):\n",
    "        ads+=1\n",
    "        pass\n",
    "    elif is_keyword_in(unrelated_keyword_path, dummy['twit']):\n",
    "        unr+=1\n",
    "        pass\n",
    "    else:\n",
    "        refined = dummy['twit']\n",
    "        refined = replace_text(replace_path, refined)\n",
    "        refined = re.sub('[-=+,#/\\:@*\\\"※ㆍ』‘|\\(\\)\\[\\]`\\'…》\\”\\“\\’·$&]', '', refined)\n",
    "        #refined = spelled_text(refined)\n",
    "        #time.sleep(1)\n",
    "        refined = ' '.join(refined.split())\n",
    "        df = df.append({'date': dummy['date'], 'time':dummy['time'].split('.')[0], 'twit' : dummy['twit'], 'refined_twit' : refined ,'twit_id' : dummy['twit_id'],}, ignore_index=True)\n",
    "        #print(df)\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d2a9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing completed\n"
     ]
    }
   ],
   "source": [
    "#print(\"num twits before remove duplicates \",len(df))\n",
    "df = df.drop_duplicates(['twit_id'], keep='first').reset_index(drop=True)\n",
    "df.to_feather('../all.ftr')\n",
    "print('Pre-processing completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89088f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b54db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retwit  1389673\n",
      "account  12846\n",
      "news  141815\n",
      "advertise  596\n",
      "unrelated  28338\n"
     ]
    }
   ],
   "source": [
    "print(\"retwit \", ret)\n",
    "print(\"account \", act)\n",
    "print(\"news \", news)\n",
    "print(\"advertise \",ads)\n",
    "print(\"unrelated \",unr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a6bb3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1573268\n"
     ]
    }
   ],
   "source": [
    "print((ret+act+news+ads+unr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2d53a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b9f435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44948\n"
     ]
    }
   ],
   "source": [
    "print((len(data)-(ret+act+news+ads+unr)) -len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99cca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(['twit_id'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7299f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['twit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "598de676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246967\n"
     ]
    }
   ],
   "source": [
    "print(len(data)-(ret+act+news+ads+unr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec5595ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197515\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a5b0494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>twit</th>\n",
       "      <th>refined_twit</th>\n",
       "      <th>twit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>22:40:01</td>\n",
       "      <td>백신 4차 노바백스로 맞음맞으면서 부작용 사례 물어보니아직 접수 된 건이 하나도 없...</td>\n",
       "      <td>백신 4차 노바백스로 맞음맞으면서 부작용 사례 물어보니아직 접수 된 건이 하나도 없...</td>\n",
       "      <td>1553510754581487616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>08:16:57</td>\n",
       "      <td>노바백스 후기화이자 보다 안 아픔 근데 팔 아파서 잘 못 움직임 근데 이것도 케바케...</td>\n",
       "      <td>노바백스 후기화이자 보다 안 아픔 근데 팔 아파서 잘 못 움직임 근데 이것도 케바케...</td>\n",
       "      <td>1553293555854061571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>04:17:49</td>\n",
       "      <td>@haruobear 오오 저 이거 너무 궁굼했어요!!!!!!!흑 4차는 저도 노바백...</td>\n",
       "      <td>오오 저 이거 너무 궁굼했어요!!!!!!!흑 4차는 저도 노바백스 맞으려고 했는데 ...</td>\n",
       "      <td>1552870990924812289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>03:27:33</td>\n",
       "      <td>@haruobear 노바백스 맞았어여??? 헉헉 괜찮으신가여?</td>\n",
       "      <td>노바백스 맞았어요??? 헉헉 괜찮으신가여?</td>\n",
       "      <td>1552858339389779968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>06:22:50</td>\n",
       "      <td>1,2차 화이자3차 노바백스생명의 위협을 느껴서 이제서야 3차 맞음근데 15분 있다...</td>\n",
       "      <td>12차 화이자3차 노바백스생명의 위협을 느껴서 이제서야 3차 맞음근데 15분 있다가...</td>\n",
       "      <td>1552540061635293184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202013</th>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>03:56:40</td>\n",
       "      <td>나 뭐냐... 격리해제 3개월 지낫는데 동절기 화이자 어쩌구 되는건가?</td>\n",
       "      <td>나 뭐냐... 격리해제 3개월 지낫는데 동절기 화이자 어쩌구 되는건가?</td>\n",
       "      <td>1607586232871321600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202014</th>\n",
       "      <td>2022-11-11</td>\n",
       "      <td>01:27:58</td>\n",
       "      <td>모더나 맞았다. 아예 오늘 외출을 하지 말라고 하시는데 음 오늘 성수동 그냥 가지말...</td>\n",
       "      <td>모더나 맞았다. 아예 오늘 외출을 하지 말라고 하시는데 음 오늘 성수동 그냥 가지말...</td>\n",
       "      <td>1590878972480741378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202015</th>\n",
       "      <td>2022-11-10</td>\n",
       "      <td>14:16:46</td>\n",
       "      <td>@moca_is_moca 모더나 많이 아프세요 모카님? 저도 내일 맞으러 가요</td>\n",
       "      <td>모더나 많이 아프세요 모카님? 저도 내일 맞으러 가요</td>\n",
       "      <td>1590710060245987329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202016</th>\n",
       "      <td>2022-08-05</td>\n",
       "      <td>15:02:44</td>\n",
       "      <td>더킹 관상 레알 준니 좋아하는영화들인데..더킹은 내 영화인생에 단연코1위 최애영화이...</td>\n",
       "      <td>더킹 관상 레알 준니 좋아하는영화들인데..더킹은 내 영화인생에 단연코1위 최애영화이...</td>\n",
       "      <td>1555570004912787456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202017</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>01:21:03</td>\n",
       "      <td>@diiidll 네!! 저는 모더나엿는데 화이자도 똑같다고 들었어요!! 음주 여부 ...</td>\n",
       "      <td>네!! 저는 모더나엿는데 화이자도 똑같다고 들었어요!! 음주 여부 안물어보셨으니가 ...</td>\n",
       "      <td>1611170953106690049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197515 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date      time  \\\n",
       "0       2022-07-30  22:40:01   \n",
       "1       2022-07-30  08:16:57   \n",
       "2       2022-07-29  04:17:49   \n",
       "3       2022-07-29  03:27:33   \n",
       "4       2022-07-28  06:22:50   \n",
       "...            ...       ...   \n",
       "202013  2022-12-27  03:56:40   \n",
       "202014  2022-11-11  01:27:58   \n",
       "202015  2022-11-10  14:16:46   \n",
       "202016  2022-08-05  15:02:44   \n",
       "202017  2023-01-06  01:21:03   \n",
       "\n",
       "                                                     twit  \\\n",
       "0       백신 4차 노바백스로 맞음맞으면서 부작용 사례 물어보니아직 접수 된 건이 하나도 없...   \n",
       "1       노바백스 후기화이자 보다 안 아픔 근데 팔 아파서 잘 못 움직임 근데 이것도 케바케...   \n",
       "2       @haruobear 오오 저 이거 너무 궁굼했어요!!!!!!!흑 4차는 저도 노바백...   \n",
       "3                      @haruobear 노바백스 맞았어여??? 헉헉 괜찮으신가여?   \n",
       "4       1,2차 화이자3차 노바백스생명의 위협을 느껴서 이제서야 3차 맞음근데 15분 있다...   \n",
       "...                                                   ...   \n",
       "202013            나 뭐냐... 격리해제 3개월 지낫는데 동절기 화이자 어쩌구 되는건가?   \n",
       "202014  모더나 맞았다. 아예 오늘 외출을 하지 말라고 하시는데 음 오늘 성수동 그냥 가지말...   \n",
       "202015        @moca_is_moca 모더나 많이 아프세요 모카님? 저도 내일 맞으러 가요   \n",
       "202016  더킹 관상 레알 준니 좋아하는영화들인데..더킹은 내 영화인생에 단연코1위 최애영화이...   \n",
       "202017  @diiidll 네!! 저는 모더나엿는데 화이자도 똑같다고 들었어요!! 음주 여부 ...   \n",
       "\n",
       "                                             refined_twit              twit_id  \n",
       "0       백신 4차 노바백스로 맞음맞으면서 부작용 사례 물어보니아직 접수 된 건이 하나도 없...  1553510754581487616  \n",
       "1       노바백스 후기화이자 보다 안 아픔 근데 팔 아파서 잘 못 움직임 근데 이것도 케바케...  1553293555854061571  \n",
       "2       오오 저 이거 너무 궁굼했어요!!!!!!!흑 4차는 저도 노바백스 맞으려고 했는데 ...  1552870990924812289  \n",
       "3                                 노바백스 맞았어요??? 헉헉 괜찮으신가여?  1552858339389779968  \n",
       "4       12차 화이자3차 노바백스생명의 위협을 느껴서 이제서야 3차 맞음근데 15분 있다가...  1552540061635293184  \n",
       "...                                                   ...                  ...  \n",
       "202013            나 뭐냐... 격리해제 3개월 지낫는데 동절기 화이자 어쩌구 되는건가?  1607586232871321600  \n",
       "202014  모더나 맞았다. 아예 오늘 외출을 하지 말라고 하시는데 음 오늘 성수동 그냥 가지말...  1590878972480741378  \n",
       "202015                      모더나 많이 아프세요 모카님? 저도 내일 맞으러 가요  1590710060245987329  \n",
       "202016  더킹 관상 레알 준니 좋아하는영화들인데..더킹은 내 영화인생에 단연코1위 최애영화이...  1555570004912787456  \n",
       "202017  네!! 저는 모더나엿는데 화이자도 똑같다고 들었어요!! 음주 여부 안물어보셨으니가 ...  1611170953106690049  \n",
       "\n",
       "[197515 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281681b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16afc9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9390c44a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:harin]",
   "language": "python",
   "name": "conda-env-harin-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
